{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "from folium.plugins import FastMarkerCluster\n",
    "import numpy as np\n",
    "import geopandas\n",
    "import rtree\n",
    "import descartes\n",
    "import geopandas as gpd\n",
    "from datetime import date, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_drivers = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filepath\n",
    "fp = \"./Cambridge_Neighborhoods.shp\"\n",
    "\n",
    "# Read the data\n",
    "pop = gpd.read_file(fp)\n",
    "pop = pop[['NAME','geometry']]\n",
    "pop=pop.to_crs(epsg=4326)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomorrow = date.today()+ timedelta(days=1)\n",
    "tomorrow = tomorrow.strftime(\"%m_%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Street #</th>\n",
       "      <th>Street Name</th>\n",
       "      <th>Apt #</th>\n",
       "      <th>Senior</th>\n",
       "      <th>New</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>820</td>\n",
       "      <td>Mass Ave</td>\n",
       "      <td>room #305</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>Churchill Ave.</td>\n",
       "      <td>507</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>856</td>\n",
       "      <td>Massachusetts Ave</td>\n",
       "      <td>#6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>Bowdoin St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>Child St</td>\n",
       "      <td>1616</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Street #        Street Name      Apt #  Senior  New\n",
       "0   1      820           Mass Ave  room #305       1    1\n",
       "1   2       30     Churchill Ave.        507       1    1\n",
       "2   3      856  Massachusetts Ave         #6       1    1\n",
       "3   4       14         Bowdoin St        NaN       1    1\n",
       "4   5       20           Child St       1616       0    1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename ='./data/' + str(tomorrow) + \"_deliveries.csv\"\n",
    "df_original = pd.read_csv(filename)\n",
    "\n",
    "df = df_original.drop(columns = ['First Name', 'Last Name', 'Notes',\n",
    "                                'Phone'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data cleaning\n",
    "df['Street_clean']=df['Street Name']\n",
    "for address in df['Street_clean']:\n",
    "    try:\n",
    "        df.loc[df.Street_clean==address,'Street_clean']=address.replace(\".\",\"\")\n",
    "        df.loc[df.Street_clean==address,'Street_clean']=address.replace(\",\",\"\")\n",
    "        df.loc[df.Street_clean==address,'Street_clean']=address.replace(\";\",\"\")\n",
    "        df.loc[df.Street_clean==address,'Street_clean']=address.replace(\"/\",\"\")\n",
    "        df.loc[df.Street_clean==address,'Street_clean']=address.rstrip()\n",
    "    except:\n",
    "        print(address)\n",
    "\n",
    "for address in df['Street_clean']:\n",
    "    try:\n",
    "        x=address.lower()\n",
    "        \n",
    "        if x[:2].isdigit():\n",
    "            df.loc[df.Street_clean==address,'Street_clean']=x[x.find(\" \"):]\n",
    "\n",
    "        if \"-\" in x:\n",
    "            df.loc[df.Street_clean==address,'Street_clean']=x[:x.find(\"-\")]\n",
    "        if \"(\" in x:\n",
    "            df.loc[df.Street_clean==address,'Street_clean']=x[:x.find(\"(\")]\n",
    "        if \"calendar stret\" in x:\n",
    "            df.loc[df.Street_clean==address,'Street_clean']=\"Callender Street\"\n",
    "        if \"alston street\" in x:\n",
    "            df.loc[df.Street_clean==address,'Street_clean']=\"Allston Street\"\n",
    "        if \"auburn\" in x:\n",
    "            df.loc[df.Street_clean==address,'Street_clean']=\"Auburn Street\"\n",
    "        if \"linwood pl\" in x:\n",
    "            df.loc[df.Street_clean==address,'Street_clean']=\"Broadway\"\n",
    "        if \"mass ave\" in x or \"\":\n",
    "            df.loc[df.Street_clean==address,'Street_clean']=\"Massachusetts Avenue\"\n",
    "        if  \"aveue\" in x:\n",
    "            df.loc[df.Street_clean==address,'Street_clean']=x[:x.find(\"aveue\")] + \"Avenue\"\n",
    "        if \"stret\" in x:\n",
    "            df.loc[df.Street_clean==address,'Street_clean']=x[:x.find(\"Stret\")] + \"Street\"\n",
    "            df.loc[df.Street_clean==address,'Street_clean']=x[:x.find(\"stret\")] + \"Street\"\n",
    "        if  \"cambridge park\" in x:\n",
    "            df.loc[df.Street_clean==address,'Street_clean']=\"Cambridgepark Drive\"\n",
    "        if \"lansdown\" in x or \"lansdowne\" in x:\n",
    "            df.loc[df.Street_clean==address,'Street_clean']=\"Landsdowne St\"\n",
    "        if \" apt \" in x :\n",
    "            df.loc[df.Street_clean==address,'Street_clean']=x[:x.find(\"apt\")]\n",
    "        if \" bldg \" in x :\n",
    "            df.loc[df.Street_clean==address,'Street_clean']=x[:x.find(\"bldg\")]\n",
    "        if x[-4:]=='bldg':\n",
    "            df.loc[df.Street_clean==address,'Street_clean']=x[:x.find(\"bldg\")]\n",
    "        if x[-3:]=='apt':\n",
    "            df.loc[df.Street_clean==address,'Street_clean']=x[:x.find(\"apt\")]\n",
    "        if \"frankln\" in x or 'franlin' in x or 'frankin' in x or \"frtanklin\" in x:\n",
    "            df.loc[df.Street_clean==address,'Street_clean']=\"Franklin Street\"\n",
    "        if \"jackon\" in x:\n",
    "            df.loc[df.Street_clean==address,'Street_clean']=\"Jackson Pl\"\n",
    "        if \"muesum\" in x:\n",
    "            df.loc[df.Street_clean==address,'Street_clean']=\"Museum Way\"\n",
    "        if \"newtown\" in x or \"newton\" in x:\n",
    "            df.loc[df.Street_clean==address,'Street_clean']=\"Main Street\"\n",
    "            df.loc[df.Street_clean==address,'Street #']=\"637\"\n",
    "        if \"eerie\" in x:\n",
    "            df.loc[df.Street_clean==address,'Street_clean']=\"Erie Street\"\n",
    "        if \"8th\" in x:\n",
    "            df.loc[df.Street_clean==address,'Street_clean']=\"Eighth Street\"\n",
    "        if \"cliffton\" in x:\n",
    "            df.loc[df.Street_clean==address,'Street_clean']=\"Clifton Place\"\n",
    "    except:\n",
    "        print(address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ADDRESS']=\"\"\n",
    "for address in df['ADDRESS']:\n",
    "    if address == \"\":\n",
    "        df['ADDRESS'] = df['Street #'].astype(str) + ' ' + \\\n",
    "                        df['Street_clean'] + ',' + \\\n",
    "                        \"Cambridge\" + ',' + \\\n",
    "                        \"Massachusetts\" + ',' + ' USA'   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_points = pd.read_csv(\"point_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1565"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_df = good_points[['ADDRESS','location', 'point', \n",
    "                          'latitude', 'longitude','altitude', \n",
    "                          'point_location']].drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_table= df.merge(smaller_df,on = ['ADDRESS'],how='left')\n",
    "bad_table = point_table.loc[point_table['point'].isnull()]\n",
    "good_table = point_table.dropna(subset=['point'], how='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328, 53, 381)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_table), len(bad_table), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geocode(df):\n",
    "    from geopy.extra.rate_limiter import RateLimiter\n",
    "    locator = Nominatim(user_agent=\"myGeocoder\")\n",
    "    geocode = RateLimiter(locator.geocode, min_delay_seconds=1)\n",
    "    df['location'] = df['ADDRESS'].apply(geocode)\n",
    "    df['point'] = df['location'].apply(lambda loc: tuple(loc.point) if loc else None)\n",
    "    \n",
    "    df[['latitude', 'longitude', 'altitude']] = pd.DataFrame(df['point'].tolist(), index=bad_table.index)\n",
    "    df['point_location'] = bad_table[\"longitude\"].astype(str) + \",\" + df[\"latitude\"].astype(str)\n",
    "\n",
    "    null_df = df.loc[df['point'].isnull()]\n",
    "    df=df.dropna(subset=['point'], how='all')\n",
    "    return df, null_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoded_table, null_table = geocode(bad_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.concat([good_table,geocoded_table])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = df_new[['latitude', 'longitude']]\n",
    "locationlist = locations.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "map1 = folium.Map(\n",
    "    location=[42.362750, -71.101182],\n",
    "    tiles='cartodbpositron',\n",
    "    zoom_start=12,\n",
    ")\n",
    "\n",
    "df_new.apply(lambda row:folium.Marker(\n",
    "    location=[row[\"latitude\"], row[\"longitude\"]]).add_to(map1), axis=1)\n",
    "\n",
    "for point in range(0, len(locationlist)):\n",
    "    folium.Marker(locationlist[point], popup=('Address: '+str(df_new['ADDRESS'][point])),\n",
    "                 icon=folium.Icon(color='blue')).add_to(map1)\n",
    "\n",
    "map1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = geopandas.GeoDataFrame(\n",
    "    df_new, geometry=geopandas.points_from_xy(df_new.longitude, df_new.latitude))\n",
    "\n",
    "df_new = gpd.sjoin(gdf, pop, how=\"left\", op=\"within\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {-1:'darkgreen',0:'darkpurple',1:'green',2:'purple',3:'red',4:'gray',5:'lightblue',\n",
    "             6:'beige',7:'cadetblue',8:'black',9:'pink',10:'darkred',11:'lightred',\n",
    "             12:'darkblue',13:'lightgreen',13:'white',14:'darkgreen',15:'darkpurple',16:'green',\n",
    "              17:'purple',18:'red',19:'gray',20:'lightblue',\n",
    "             21:'beige',22:'cadetblue',23:'black',24:'pink',25:'darkred',26:'lightred',\n",
    "             27:'darkblue',28:'lightgreen',29:'white',30:'gray',31:'cadetblue',32:'orange',33:'green',\n",
    "              34:'white',35:'darkgreen'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.loc[df_new['NAME'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_cambridge_df = df_new.loc[df_new['NAME'].isnull()]\n",
    "null_table = pd.concat([null_table,not_cambridge_df])\n",
    "df_new = df_new.dropna(subset=['NAME'], how='all')\n",
    "\n",
    "len(null_table), len(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighborhood_clean(df):\n",
    "    neighborhood_list_temp = []\n",
    "    \n",
    "    neighborhood_list = ['The Port','Neighborhood Nine','Area 2/MIT',\n",
    "                    'Cambridgeport','Riverside','Mid-Cambridge',\n",
    "                    'Wellington-Harrington','East Cambridge','Agassiz','Cambridge Highlands',\n",
    "                    'Strawberry Hill','West Cambridge','North Cambridge']\n",
    "    \n",
    "    for x in df_new['NAME']:\n",
    "        z=0\n",
    "        for y in neighborhood_list:\n",
    "            if y in str(x):\n",
    "                if y in [\"Cambridge Highlands\",\"West Cambridge\", \"Strawberry Hill\"]:\n",
    "                    neighborhood_list_temp.append('North Cambridge')\n",
    "                elif y in [\"Agassiz\",\"Neighborhood Nine\",\"Riverside\"]:\n",
    "                    neighborhood_list_temp.append('Mid-Cambridge')\n",
    "                elif y == \"Area 2/MIT\":\n",
    "                    neighborhood_list_temp.append('Cambridgeport')\n",
    "                elif y in [\"Wellington-Harrington\",\"The Port\"]:\n",
    "                    neighborhood_list_temp.append('East Cambridge')\n",
    "                else: \n",
    "                    neighborhood_list_temp.append(y)\n",
    "                z=1\n",
    "                break\n",
    "        if z==0:\n",
    "            neighborhood_list_temp.append('Problem Location')\n",
    "        \n",
    "    return neighborhood_list_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['neighborhood']=neighborhood_clean(df_new)\n",
    "df_new['neighborhood'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_color_dict = {'Cambridgeport':'darkgreen','East Cambridge':'darkpurple',\n",
    "                           'North Cambridge':'purple','Mid-Cambridge':'black',\n",
    "                           'Problem Location':'red'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['neighborhood_color']=df_new['neighborhood'].map(neighborhood_color_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_map_name = 'DeliveryNeighborhoods_' + str(tomorrow) + '.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.reset_index()\n",
    "locations = df_new[['latitude', 'longitude']]\n",
    "locationlist = locations.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "map = folium.Map(location=[42.379750, -71.101182], zoom_start=13)\n",
    "for point in range(0, len(locationlist)):\n",
    "    folium.Marker(locationlist[point], popup=('Driver Group: '+str(df_new['neighborhood'][point])),\n",
    "                 icon=folium.Icon(color=df_new[\"neighborhood_color\"][point])).add_to(map)\n",
    "    \n",
    "map.save(neighborhood_map_name)\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one hot encoding of columns B\n",
    "one_hot = pd.get_dummies(df_new['neighborhood'])\n",
    "# Drop column B as it is now encoded\n",
    "df_new = df_new.drop('neighborhood',axis = 1)\n",
    "# Join the encoded df\n",
    "df_new = df_new.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kmeans(df, n_clusters, min_size, max_size):\n",
    "    from k_means_constrained import KMeansConstrained\n",
    "    df_temp = df[['latitude', 'longitude']]\n",
    "    # Convert DataFrame to matrix\n",
    "    mat = df_temp.values\n",
    "    # Using sklearn\n",
    "    km = KMeansConstrained(\n",
    "         n_clusters=n_clusters,\n",
    "         size_min=min_size,\n",
    "         size_max=max_size,\n",
    "         random_state=0\n",
    "    ).fit(mat)\n",
    "    # Get cluster assignment labels\n",
    "    labels = km.labels_\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.sort_values(['Senior'])\n",
    "df_seniors = df_new.loc[df_new['Senior']==1]\n",
    "df_nonseniors = df_new.loc[df_new['Senior']!=1]\n",
    "senior_clusters = int(round(len(df_seniors)/10,0))\n",
    "nonsenior_clusters = number_drivers - senior_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senior_labels = run_kmeans(df_seniors, int(senior_clusters),9,12)\n",
    "df_nonsenior_labels = run_kmeans(df_nonseniors, int(nonsenior_clusters),9,12)\n",
    "df_nonsenior_labels = df_nonsenior_labels + senior_clusters\n",
    "\n",
    "all_labels = np.concatenate([df_nonsenior_labels, df_senior_labels])\n",
    "df_new['kmeans_cluster'] = all_labels\n",
    "df_new['kmeans_cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seniors['kmeans_cluster'] = df_senior_labels\n",
    "\n",
    "df_seniors = df_seniors.drop(columns = ['level_0'])\n",
    "df_seniors = df_seniors.reset_index()\n",
    "\n",
    "senior_locations = df_seniors[['latitude', 'longitude']]\n",
    "seniorlocationlist = senior_locations.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seniors['kmeans_color']=df_seniors['kmeans_cluster'].map(color_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = folium.Map(location=[42.379750, -71.101182], zoom_start=13)\n",
    "for point in range(0, len(seniorlocationlist)):\n",
    "    folium.Marker(seniorlocationlist[point], popup=('Driver Group: '+str(df_seniors['kmeans_cluster'][point])),\n",
    "                 icon=folium.Icon(color=df_seniors[\"kmeans_color\"][point])).add_to(map)\n",
    "    \n",
    "#map.save(delivery_map_name)\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['kmeans_color']=df_new['kmeans_cluster'].map(color_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_map_name = 'DeliveryMaps_' + str(tomorrow) + '.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "map = folium.Map(location=[42.379750, -71.101182], zoom_start=13)\n",
    "for point in range(0, len(locationlist)):\n",
    "    folium.Marker(locationlist[point], popup=('Driver Group: '+str(df_new['kmeans_cluster'][point])),\n",
    "                 icon=folium.Icon(color=df_new[\"kmeans_color\"][point])).add_to(map)\n",
    "    \n",
    "map.save(delivery_map_name)\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['Driver_ID']=df_new['kmeans_cluster']\n",
    "null_table['Driver_ID']=99\n",
    "\n",
    "df_new = df_new[['ID','Street #', 'Street Name', 'Apt #', 'Senior',\n",
    "       'New','location', 'latitude','longitude','Driver_ID']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_table = pd.concat([null_table,df_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_table_final = driver_table.merge(df_original[['ID','First Name', 'Last Name', 'Notes',\n",
    "                                'Phone']], on = 'ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_table_final=driver_table_final[['ID','First Name', 'Last Name',\n",
    "                                        'Street #','Street Name','Apt #',\n",
    "                                        'Driver_ID', 'New','Senior','Phone',\n",
    "                                        'Notes','location','latitude','longitude']].sort_values(by = ['Driver_ID', 'Street Name', \n",
    "                                                       'Street #', 'Apt #'],ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_final = \"./delivery routes/Driver_Table_\" + str(tomorrow) + \".xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_table_final.to_excel(file_name_final, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from shapely.ops import nearest_points\n",
    "# unary union of the gpd2 geomtries \n",
    "#boundary = pop2[\"geometry\"].unary_union\n",
    "\n",
    "#def near(point, pts=boundary):\n",
    "     # find the nearest point and return the corresponding Place value\n",
    "#    nearest = pop2.geometry == nearest_points(point, pts)[1]\n",
    "#    print(nearest)\n",
    "#    return pop2[nearest].NAME\n",
    "\n",
    "\n",
    "#df_new_join = gpd.sjoin(gdf, pop2, how=\"left\", op=\"within\")\n",
    "#df_noncambridge = df_new_join.loc[df_new_join['NAME'].isnull()]['geometry']\n",
    "#df_noncambridge.geometry\n",
    "#pop2['centroid'] = pop2.centroid\n",
    "\n",
    "#def nearest(row, geom_union, df1, df2, geom1_col='geometry', geom2_col='geometry', src_column=None):\n",
    "    #\"\"\"Find the nearest point and return the corresponding value from specified column.\"\"\"\n",
    "    # Find the geometry that is closest\n",
    "   # nearest = df2[geom2_col] == nearest_points(row[geom1_col], geom_union)[1]\n",
    "    # Get the corresponding value from df2 (matching is based on the geometry)\n",
    "  #  value = df2[nearest][src_column].get_values()[0]\n",
    " #   return value\n",
    "\n",
    "\n",
    "#unary_union = df_noncambridge.unary_union\n",
    "\n",
    "#df_noncambridge['nearest_id'] = pop2.apply(nearest, \n",
    "  #                            geom_union=unary_union, \n",
    " #                             df1=pop2, df2=df_noncambridge, geom1_col='centroid')\n",
    "\n",
    "#def min_distance(point, polygons):\n",
    "  #  x = polygons.distance(point).min()\n",
    " #   return x\n",
    "\n",
    "#df_noncambridge['min_dist_to_lines'] = df_noncambridge.geometry.apply(min_distance, pop2)\n",
    "\n",
    "#for x in df_new_join.loc[df_new_join['NAME'].isnull()]['geometry']:\n",
    " #   print(min_distance(x, pop2))\n",
    "    \n",
    "    \n",
    "#from shapely.ops import nearest_points\n",
    "# unary union of the gpd2 geomtries \n",
    "#pts3 = gpd2.geometry.unary_union\n",
    "#def near(point, pts=pts3):\n",
    "     # find the nearest point and return the corresponding Place value\n",
    "  #  nearest = gpd2.geometry == nearest_points(point, pts)[1]\n",
    " #   return gpd2[nearest].Place.get_values()[0]\n",
    "\n",
    "#gpd1['Nearest'] = gpd1.apply(lambda row: near(row.geometry), axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
